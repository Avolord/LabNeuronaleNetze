{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61e7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79b458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "namedf = pd.read_csv(\"surnames_with_splits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e37e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, dataframe, ngram_len=3):\n",
    "        \n",
    "        #self.X will be an n-tuple of characters\n",
    "        #self.Y will be the next character after the n-tuple\n",
    "        \n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        for i, row in dataframe.iterrows():\n",
    "            name = f\"#{row['surname'].lower()}$\" #add a # at the beginning and end of the name to indicate the start and end of the name\n",
    "            if (len(name) + 1) < (ngram_len + 1):\n",
    "                continue\n",
    "            \n",
    "            for i in range(len(name)-ngram_len):\n",
    "                self.X.append(name[i:i+ngram_len])\n",
    "                self.Y.append(name[i+ngram_len])\n",
    "        \n",
    "    def vectorize_name(self, trigram):\n",
    "        pass\n",
    "        #return ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "       \n",
    "        x = self.X[index]\n",
    "        y = self.Y[index]\n",
    "        \n",
    "        return x,y\n",
    "\n",
    "def get_trigram_loader(dataframe, batch_size=16, shuffle=True):\n",
    "    'returns a DataLoader instance with the given parameters'\n",
    "    dataset = LMDataset(dataframe, ngram_len = 3)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c207caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_trigram_loader(namedf[namedf.split == 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11679d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramLMOneHot(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, vocab_dim):\n",
    "       \n",
    "        super(TrigramLMOneHot, self).__init__()\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(vocab_dim*3,hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_dim)\n",
    "        self.sm = nn.Softmax(dim=1) # softmax über output nodes/spalten deswegen dim=1    \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x_in):\n",
    "        x = self.hidden_layer(x_in)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return self.sm(x) \n",
    "    \n",
    " # https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4055f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(start: chr, end: chr, dataframe: pd.DataFrame):\n",
    "    names = dataframe.surname.str.lower()\n",
    "    \n",
    "    vocab = {start: 0, end: 1}\n",
    "    for name in names:\n",
    "        for c in name:\n",
    "            if c not in vocab:\n",
    "                vocab[c] = len(vocab)\n",
    "                \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff3b03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_chars = list(string.ascii_lowercase) + ['ä', 'ö', 'ü', 'ß']\n",
    "\n",
    "vocab = build_vocab('#', '$', namedf)\n",
    "trilm = TrigramLMOneHot(128, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75fae5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#': 0, '$': 1, 't': 2, 'o': 3, 'a': 4, 'h': 5, 'b': 6, 'u': 7, 'd': 8, 'f': 9, 'k': 10, 'r': 11, 'y': 12, 's': 13, 'e': 14, 'g': 15, 'c': 16, 'm': 17, 'i': 18, 'n': 19, 'w': 20, 'l': 21, 'z': 22, 'q': 23, 'j': 24, '-': 25, 'p': 26, 'x': 27, ':': 28, 'v': 29, '1': 30, '/': 31, 'é': 32, \"'\": 33, 'ç': 34, 'ê': 35, 'ß': 36, 'ö': 37, 'ä': 38, 'ü': 39, 'ú': 40, 'à': 41, 'ò': 42, 'è': 43, 'ó': 44, 'ù': 45, 'ì': 46, 'ś': 47, 'ą': 48, 'ń': 49, 'á': 50, 'ż': 51, 'ł': 52, 'õ': 53, 'ã': 54, 'í': 55, 'ñ': 56}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4babe823",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.3\n",
    "optimizer = optim.Adam(params=trilm.parameters(), lr=lr)\n",
    "ce_loss = nn.NLLLoss()\n",
    "epoch = 0  # reset epoch counter\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6437dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_trigrams(trigrams: list[str], vocab: dict[chr, int]):\n",
    "    vecs = []\n",
    "    len_vocab = len(vocab)\n",
    "    for trigram in trigrams:\n",
    "        vec = torch.zeros(3*len_vocab)\n",
    "        for i, char in enumerate(trigram):\n",
    "            vec[i*len_vocab + vocab[char]] = 1\n",
    "        vecs.append(vec)\n",
    "    return torch.stack(vecs)\n",
    "\n",
    "def target_to_indicies(chars: list[chr], vocab: dict[chr, int]):\n",
    "    vec = []\n",
    "    for char in chars:\n",
    "        vec.append(vocab[char])\n",
    "    return torch.tensor(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3f5cb6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0\n",
      "Loss :  -217.9375\n",
      "Epoch :  1\n",
      "Loss :  -217.9375\n",
      "Epoch :  2\n",
      "Loss :  -217.9375\n",
      "Epoch :  3\n",
      "Loss :  -217.98611111193895\n",
      "Epoch :  4\n",
      "Loss :  -218.0347222238779\n",
      "Epoch :  5\n",
      "Loss :  -217.9375\n",
      "Epoch :  6\n",
      "Loss :  -217.98611111193895\n",
      "Epoch :  7\n",
      "Loss :  -217.9375\n",
      "Epoch :  8\n",
      "Loss :  -217.9375\n",
      "Epoch :  9\n",
      "Loss :  -217.9375\n"
     ]
    }
   ],
   "source": [
    "#For each epoch\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch : ', epoch)\n",
    "    sum_loss=0\n",
    "    \n",
    "    #For each batch\n",
    "    for batch_index, (x,y) in enumerate(train_loader):\n",
    "        #print(x, x.type(), x.size())\n",
    "    \n",
    "        #reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #prepare the x as tensor\n",
    "        x = vectorize_trigrams(x, vocab)\n",
    "        y = target_to_indicies(y, vocab)\n",
    "        \n",
    "        #run the model, get the prediction for x\n",
    "        y_pred = trilm(x)\n",
    "        \n",
    "        #print the dimensions of x, y, y_pred\n",
    "        #print(x.size(), y.size(), y_pred.size())\n",
    "        \n",
    "        #compare it with label, calculate loss, add it to epoch loss\n",
    "        loss=ce_loss(y_pred, y)\n",
    "        sum_loss+=loss.item()\n",
    "        \n",
    "        #calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        #call optimizer to update the weights backwards \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Loss : ', sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2041006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Maximum length reached\n",
      "final name: aanaaaaaaaaaaaa\n"
     ]
    }
   ],
   "source": [
    "def generate_name(model: nn.Module, prefix: str, vocab: dict[chr, int]):\n",
    "    model.eval()\n",
    "    name = prefix\n",
    "    \n",
    "    #limit the length of the generated text to 15 characters\n",
    "    while len(name) < 15:\n",
    "        #vectorize the last 3 characters of the generated text\n",
    "        x = vectorize_trigrams([name[-3:]], vocab)\n",
    "        \n",
    "        #run the model, get the prediction for x\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        #if sample is True, sample the next character from the predicted probabilities\n",
    "        y_pred = torch.argmax(y_pred, dim=1).detach().numpy()[0]\n",
    "        \n",
    "        #get the character corresponding to the index\n",
    "        char = list(vocab.keys())[list(vocab.values()).index(y_pred)]\n",
    "        \n",
    "        if char == '$':\n",
    "            break\n",
    "        elif char == '#':\n",
    "            print(\"Error: Start character found in the middle of the name\")\n",
    "            break\n",
    "        \n",
    "        #add the character to the generated text\n",
    "        name += char\n",
    "    \n",
    "    if(len(name) == 15):\n",
    "        print(\"Error: Maximum length reached\")\n",
    "    print(f\"final name: {name}\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
