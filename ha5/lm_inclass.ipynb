{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bcf1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab99921",
   "metadata": {},
   "outputs": [],
   "source": [
    "namedf = pd.read_csv(\"surnames_with_splits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82743271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>nationality_index</th>\n",
       "      <th>split</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Totah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Abboud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Fakhoury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Srour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Sayegh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Dinh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Phung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Quang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Vu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>Ha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nationality  nationality_index  split   surname\n",
       "0          Arabic                 15  train     Totah\n",
       "1          Arabic                 15  train    Abboud\n",
       "2          Arabic                 15  train  Fakhoury\n",
       "3          Arabic                 15  train     Srour\n",
       "4          Arabic                 15  train    Sayegh\n",
       "...           ...                ...    ...       ...\n",
       "10975  Vietnamese                 11   test      Dinh\n",
       "10976  Vietnamese                 11   test     Phung\n",
       "10977  Vietnamese                 11   test     Quang\n",
       "10978  Vietnamese                 11   test        Vu\n",
       "10979  Vietnamese                 11   test        Ha\n",
       "\n",
       "[10980 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885ac161",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 3 (407421450.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    def vectorize_name(self,trigram):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 3\n"
     ]
    }
   ],
   "source": [
    "class LMDataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self,dataframe):\n",
    "        \n",
    "                \n",
    "        #self.X = ...\n",
    "        #self.Y = ...\n",
    "        \n",
    "    def vectorize_name(self,trigram):\n",
    "        \n",
    "        #return ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        #return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "       \n",
    "        x = self.X[index]\n",
    "        y = self.Y[index]\n",
    "        \n",
    "        return x,y\n",
    "\n",
    "def get_loader(dataframe, batch_size=16, shuffle=True):\n",
    "    'returns a DataLoader instance with the given parameters'\n",
    "    dataset = LMDataset(dataframe)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d498636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramLMOneHot(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, vocab_dim):\n",
    "       \n",
    "        super(TrigramLMOneHot, self).__init__()\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(vocab_dim*3,hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_dim)\n",
    "        self.sm = nn.Softmax(dim=1) # softmax über output nodes/spalten deswegen dim=1    \n",
    "\n",
    "    def forward(self, x_in):\n",
    "        \n",
    "        x = self.hidden_layer(x_in)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return self.sm(x) \n",
    "    \n",
    "    \n",
    " # https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trilm = TrigramLMOneHot(10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca580506",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_x = torch.tensor([[0.,1.,1.,0.,0.,1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48969e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4252, 0.5748]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trilm(trial_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0158, -0.0628,  0.3137,  0.0865,  0.0375, -0.3028],\n",
       "         [ 0.3559,  0.1028, -0.2616,  0.1874, -0.3832,  0.1978],\n",
       "         [-0.0655, -0.3617, -0.1292,  0.2155,  0.1781,  0.0625],\n",
       "         [ 0.1485,  0.3845, -0.1732,  0.1940,  0.1259,  0.3541],\n",
       "         [ 0.3923, -0.1236, -0.0380, -0.0767, -0.2842,  0.1664],\n",
       "         [-0.3430,  0.2940, -0.2840, -0.2097, -0.3190,  0.3057],\n",
       "         [-0.0241, -0.0845,  0.1926, -0.0720,  0.4026, -0.0905],\n",
       "         [-0.1535,  0.3562,  0.2219,  0.0493, -0.3052,  0.3850],\n",
       "         [-0.0145,  0.3299, -0.2035, -0.3052,  0.2326, -0.1636],\n",
       "         [ 0.1593, -0.1346,  0.3602, -0.0137, -0.4006,  0.0246]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2550, -0.1711,  0.0713,  0.3085, -0.1851, -0.3092, -0.0190, -0.2625,\n",
       "          0.1267,  0.2011], requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trilm.hidden_layer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd8a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c8cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96124213",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "optimizer = optim.Adam(params=trilm.parameters(), lr=lr)\n",
    "ce_loss = nn.NLLLoss()\n",
    "epoch = 0  # reset epoch counter\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9405f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each epoch\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch : ', epoch)\n",
    "    sum_loss=0\n",
    "    \n",
    "    #For each batch\n",
    "    for batch_index, (x,y) in enumerate(train_loader):\n",
    "        #print(x, x.type(), x.size())\n",
    "    \n",
    "        #reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #prepare the x as tensor\n",
    "        \n",
    "        #run the model, get the prediction for x\n",
    "        y_pred = trilm(x)\n",
    "        \n",
    "        #print(y_pred)\n",
    "        \n",
    "        #compare it with label, calculate loss, add it to epoch loss\n",
    "        loss=ce_loss(y_pred, y)\n",
    "        sum_loss+=loss.item()\n",
    "        \n",
    "        #calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        #call optimizer to update the weights backwards \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Loss : ', sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a60a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_trigram(trigram,start=False):\n",
    "    \n",
    "    if start:\n",
    "        return [vocab['START']]+[vocab[char] for char in trigram]\n",
    "\n",
    "    return [vocab[char] for char in trigram]\n",
    "\n",
    "\n",
    "def generate_char(model, bigram_prefix,sample=False):\n",
    "    #sample_generated_text= prefix\n",
    "    #greedy_generated_text= prefix\n",
    "    \n",
    "    \n",
    "    prefix_generated = bigram_prefix\n",
    "    \n",
    "    while len(prefix_generated) < 15:\n",
    "        print(prefix_generated)\n",
    "        model.eval()\n",
    "        if len(prefix) < 3:\n",
    "            prefix_ids = torch.tensor(vectorize_trigram(prefix_generated,start=True))\n",
    "        else:\n",
    "            prefix_ids = torch.tensor(vectorize_trigram(prefix_generated,start=False))\n",
    "        inp=prefix_ids[-3:]\n",
    "        \n",
    "        #print('last 3 chars', inp, 'shape:', inp.size)\n",
    "        y_pred=model(inp)\n",
    "        #print(y_pred, len(y_pred))\n",
    "        #print(y_pred.exp(), len(y_pred))\n",
    "        \n",
    "        if sample:\n",
    "            top1 = torch.multinomial(y_pred.exp(),1).detach().numpy()[0][0]\n",
    "        else:\n",
    "            top1 = torch.argmax(y_pred, dim=1).detach().numpy()[0]\n",
    "            #print(top_1)\n",
    "        \n",
    "        \n",
    "        prefix_generated += idx_to_token[top1]\n",
    "        print(prefix_generated)\n",
    "        \n",
    "        if idx_to_token[top1] == \"END\":\n",
    "            break\n",
    "    \n",
    "    print(\"generated:\",prefix_generated)\n",
    "    return  prefix_generated\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
